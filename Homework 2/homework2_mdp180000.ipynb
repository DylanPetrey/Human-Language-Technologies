{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring NLTK**\n",
        "Michael Petrey"
      ],
      "metadata": {
        "id": "BOaGbt13ETgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create a Python notebook (Jupyter or Colab) with appropriate headings. You will later print-to-\n",
        "pdf for uploading. Note: intersperse all the code cells below with text cells that use markdown\n",
        "to describe what the code is doing and its output. Make sure that your notebook displays the\n",
        "code output.\n",
        "\n",
        "\n",
        "2. If you use Jupyter notebook with NLTK and libraries installed plus the nltk book download, you\n",
        "are good to go. If you use Colab, insert a code chunk at the top of your notebook to install these\n",
        "items:\n",
        "import nltk\n",
        "nltk.download(‘stopwords’)\n",
        "nltk.download(‘wordnet’)\n",
        "nltk.download(‘punkt’)\n",
        "ntlk.download(‘omw-1.4’)"
      ],
      "metadata": {
        "id": "qxyhuYS7HrV9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epzxXL6KCyzF"
      },
      "outputs": [],
      "source": [
        "from nltk import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Code cell: Each of the built-in 9 texts is an NLTK Text object. Look at the code for the Text object\n",
        "at this link: https://www.nltk.org/_modules/nltk/text.html. Look at the tokens() method. Extract\n",
        "the first 20 tokens from text1. List two things you learned about the tokens() method or Text\n",
        "objects in the text cell above this code cell.\n"
      ],
      "metadata": {
        "id": "m8VWQkwcHxtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.book import *\n",
        "text1.tokens[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlniPKqDDQzz",
        "outputId": "ca7f04d8-93ed-44ba-d4b5-53434e559076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[',\n",
              " 'Moby',\n",
              " 'Dick',\n",
              " 'by',\n",
              " 'Herman',\n",
              " 'Melville',\n",
              " '1851',\n",
              " ']',\n",
              " 'ETYMOLOGY',\n",
              " '.',\n",
              " '(',\n",
              " 'Supplied',\n",
              " 'by',\n",
              " 'a',\n",
              " 'Late',\n",
              " 'Consumptive',\n",
              " 'Usher',\n",
              " 'to',\n",
              " 'a',\n",
              " 'Grammar']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Look at the concordance() method in the API. Using the documentation to guide you, in code,\n",
        "print a concordance for text1 word 'sea', selecting only 5 lines\n"
      ],
      "metadata": {
        "id": "0xqQbSQvH1Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1.concordance('sea', 75,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWMjNwcSEEc9",
        "outputId": "e183dc3c-6d6f-4c68-a84f-d079c5194762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 5 of 455 matches:\n",
            "hall slay the dragon that is in the sea .\" -- ISAIAH \" And what thing soeve\n",
            " PLUTARCH ' S MORALS . \" The Indian Sea breedeth the most and the biggest f\n",
            "ly had we proceeded two days on the sea , when about sunrise a great many W\n",
            "ny Whales and other monsters of the sea , appeared . Among the former , one\n",
            "aves on all sides , and beating the sea before him into a foam .\" -- TOOKE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Code cell: Look at the count() method in the API. How does this work, and how is it different or\n",
        "the same as Python's count method? Write your commentary above the code cell. In the code\n",
        "cells, experiment with both count() methods."
      ],
      "metadata": {
        "id": "vx2BLO0tH590"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the NLTK API, the count function works by counting the number of tokens in the text that equal the desired word. In Python, the count function counts the number of elements in the text that equal the search term."
      ],
      "metadata": {
        "id": "6cWz1RZOE6yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = 'Hi this is a sample text'\n",
        "\n",
        "sample_tokens = word_tokenize(sample_text)\n",
        "\n",
        "# nltk\n",
        "print(sample_text.count('a'))\n",
        "\n",
        "\n",
        "# python\n",
        "print(sample_tokens.count('a'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onAKGYSeERCG",
        "outputId": "a27a038b-bc4f-4e22-9db1-f47f33ef4c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Code cell: Using raw text of at least 5 sentences of your choice from any source (cite the source),\n",
        "save the text into a variable called raw_text. Using NLTK's word tokenizer, tokenize the text into\n",
        "variable 'tokens'. Print the first 10 tokens.\n",
        "\n",
        "Source: Herbert, Frank. Dune. Hodder Paperback, 2006."
      ],
      "metadata": {
        "id": "UIOSGHHzIMtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "raw_text = \"A beginning is the time for taking the most delicate care that the balances are correct. This every sister of the Bene Gesserit knows. To begin your study of the life of MuadDib, then, take care that you first place him in his time: born in the 57th year of the Padishah Emperor, Shaddam IV. And take the most special care that you locate Muad'Dib in his place: the planet Arrakis. Do not be deceived by the fact that he was born on Caladan and lived his first fifteen years there. Arrakis, the planet known as Dune, is forever his place.\"\n",
        "\n",
        "tokens = word_tokenize(raw_text)\n",
        "\n",
        "tokens[:20]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk7znD8fILpW",
        "outputId": "573f3c92-67d7-47e2-9aa8-9943b15bd92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'beginning',\n",
              " 'is',\n",
              " 'the',\n",
              " 'time',\n",
              " 'for',\n",
              " 'taking',\n",
              " 'the',\n",
              " 'most',\n",
              " 'delicate',\n",
              " 'care',\n",
              " 'that',\n",
              " 'the',\n",
              " 'balances',\n",
              " 'are',\n",
              " 'correct',\n",
              " '.',\n",
              " 'This',\n",
              " 'every',\n",
              " 'sister']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Code cell: Using the same raw text, and NLTK's sentence tokenizer sent_tokenize(), perform\n",
        "sentence segmentation and display the sentences."
      ],
      "metadata": {
        "id": "0Uh7QnpCL-Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader.tagged import sent_tokenize\n",
        "\n",
        "sent_tokenize(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epe0a7yOL_JT",
        "outputId": "76a6a86f-f3e2-499f-f323-5c5584ebf531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A beginning is the time for taking the most delicate care that the balances are correct.',\n",
              " 'This every sister of the Bene Gesserit knows.',\n",
              " 'To begin your study of the life of MuadDib, then, take care that you first place him in his time: born in the 57th year of the Padishah Emperor, Shaddam IV.',\n",
              " \"And take the most special care that you locate Muad'Dib in his place: the planet Arrakis.\",\n",
              " 'Do not be deceived by the fact that he was born on Caladan and lived his first fifteen years there.',\n",
              " 'Arrakis, the planet known as Dune, is forever his place.']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Code cell: Using NLTK's PorterStemmer(), write a list comprehension to stem the text. Display\n",
        "the list."
      ],
      "metadata": {
        "id": "nznSWxBQMVhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import *\n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "stem = [stemmer.stem(plural) for plural in tokens]\n",
        "print(stem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2sJVw8aMTsJ",
        "outputId": "b4699067-0d8e-49aa-9db5-c2a36ebf13b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'begin', 'is', 'the', 'time', 'for', 'take', 'the', 'most', 'delic', 'care', 'that', 'the', 'balanc', 'are', 'correct', '.', 'thi', 'everi', 'sister', 'of', 'the', 'bene', 'gesserit', 'know', '.', 'to', 'begin', 'your', 'studi', 'of', 'the', 'life', 'of', 'muaddib', ',', 'then', ',', 'take', 'care', 'that', 'you', 'first', 'place', 'him', 'in', 'hi', 'time', ':', 'born', 'in', 'the', '57th', 'year', 'of', 'the', 'padishah', 'emperor', ',', 'shaddam', 'iv', '.', 'and', 'take', 'the', 'most', 'special', 'care', 'that', 'you', 'locat', \"muad'dib\", 'in', 'hi', 'place', ':', 'the', 'planet', 'arraki', '.', 'do', 'not', 'be', 'deceiv', 'by', 'the', 'fact', 'that', 'he', 'wa', 'born', 'on', 'caladan', 'and', 'live', 'hi', 'first', 'fifteen', 'year', 'there', '.', 'arraki', ',', 'the', 'planet', 'known', 'as', 'dune', ',', 'is', 'forev', 'hi', 'place', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Code cell: Using NLTK's WordNetLemmatizer, write a list comprehension to lemmatize the text.\n",
        "Display the list. In the text cell above this code cell, list at least 5 differences you see in the\n",
        "stems verses the lemmas. \n",
        "\n",
        "You can just write them each on a line, like this:\n",
        "\n",
        "stem-lemma"
      ],
      "metadata": {
        "id": "sE0HHz_TMgrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_lemma = [ WordNetLemmatizer().lemmatize(token) for token in tokens ]\n",
        "print(token_lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzXMZcxxMgCR",
        "outputId": "f8a1d580-318f-4252-f206-bb2b574bdd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'beginning', 'is', 'the', 'time', 'for', 'taking', 'the', 'most', 'delicate', 'care', 'that', 'the', 'balance', 'are', 'correct', '.', 'This', 'every', 'sister', 'of', 'the', 'Bene', 'Gesserit', 'know', '.', 'To', 'begin', 'your', 'study', 'of', 'the', 'life', 'of', 'MuadDib', ',', 'then', ',', 'take', 'care', 'that', 'you', 'first', 'place', 'him', 'in', 'his', 'time', ':', 'born', 'in', 'the', '57th', 'year', 'of', 'the', 'Padishah', 'Emperor', ',', 'Shaddam', 'IV', '.', 'And', 'take', 'the', 'most', 'special', 'care', 'that', 'you', 'locate', \"Muad'Dib\", 'in', 'his', 'place', ':', 'the', 'planet', 'Arrakis', '.', 'Do', 'not', 'be', 'deceived', 'by', 'the', 'fact', 'that', 'he', 'wa', 'born', 'on', 'Caladan', 'and', 'lived', 'his', 'first', 'fifteen', 'year', 'there', '.', 'Arrakis', ',', 'the', 'planet', 'known', 'a', 'Dune', ',', 'is', 'forever', 'his', 'place', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differences:\n",
        "\n",
        "\n",
        "1.   a-A\n",
        "2.   begin-beginning\n",
        "3.   take-taking\n",
        "4.   delic-delicate \n",
        "5.   balanc-balance"
      ],
      "metadata": {
        "id": "feduvBdJMn68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Comment cell: Write a paragraph outlining:\n",
        "\n",
        "a. your opinion of the functionality of the NLTK library\n",
        "\n",
        "b. your opinion of the code quality of the NLTK library\n",
        "\n",
        "c. a list of ways you may use NLTK in future projects"
      ],
      "metadata": {
        "id": "_7MHK8urNVHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, nltk has been relatively straight forward. All of the functions are intuitive and well documented. NLTK would be useful for projects using sentiment analysis and speech recognition."
      ],
      "metadata": {
        "id": "PyxU7fcSNWOO"
      }
    }
  ]
}