{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet is a database of Nouns, Verbs, Adjectives,and Adverbs that is organized in a hierachy. Each entry includes a short definition, synonyms, use examples, and relations to other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: memory.n.01(something that is remembered)  \n",
      "\t Lemmas:['memory']\n",
      "Synset: memory.n.02(the cognitive processes whereby past experience is remembered)  \n",
      "\t Lemmas:['memory', 'remembering']\n",
      "Synset: memory.n.03(the power of retaining and recalling past experience)  \n",
      "\t Lemmas:['memory', 'retention', 'retentiveness', 'retentivity']\n",
      "Synset: memory.n.04(an electronic memory device)  \n",
      "\t Lemmas:['memory', 'computer_memory', 'storage', 'computer_storage', 'store', 'memory_board']\n",
      "Synset: memory.n.05(the area of cognitive psychology that studies memory processes)  \n",
      "\t Lemmas:['memory']\n"
     ]
    }
   ],
   "source": [
    "# Pick a synsets\n",
    "memory = wn.synsets('memory')\n",
    "\n",
    "#  Output all the synsets\n",
    "memory_synsets = wn.synsets('memory', pos=wn.NOUN)\n",
    "for sense in memory_synsets:\n",
    "    lemmas = [l.name() for l in sense.lemmas()]\n",
    "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an electronic memory device\n",
      "['a memory and the CPU form the central part of a computer to which peripherals are attached']\n",
      "[Lemma('memory.n.04.memory'), Lemma('memory.n.04.computer_memory'), Lemma('memory.n.04.storage'), Lemma('memory.n.04.computer_storage'), Lemma('memory.n.04.store'), Lemma('memory.n.04.memory_board')]\n",
      "Synset('hardware.n.03')\n",
      "Synset('component.n.03')\n",
      "Synset('part.n.02')\n",
      "Synset('object.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "memory = wn.synset('memory.n.04')\n",
    "\n",
    "print(memory.definition())\n",
    "print(memory.examples())\n",
    "print(memory.lemmas())\n",
    "\n",
    "# WordNet hierarchy \n",
    "hyp = memory.hypernyms()[0]\n",
    "top = memory.root_hypernyms()[0]\n",
    "while hyp:\n",
    "    print(hyp)\n",
    "    if hyp == top:\n",
    "        break\n",
    "    if hyp.hypernyms():\n",
    "        hyp = hyp.hypernyms()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouns are organized in a hierachy based on the hypernymy/hyponymy relation between synsets. Nouns are all highly-connected with one another and connect to the top-most level labeled 'entity'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('hardware.n.03'), Synset('memory_device.n.01')]\n",
      "[Synset('non-volatile_storage.n.01'), Synset('read-only_memory.n.01'), Synset('real_storage.n.01'), Synset('scratchpad.n.01'), Synset('virtual_memory.n.01'), Synset('volatile_storage.n.01')]\n",
      "[Synset('register.n.04')]\n",
      "[Synset('computer.n.01')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(memory.hypernyms())\n",
    "print(memory.hyponyms())\n",
    "print(memory.part_meronyms())\n",
    "print(memory.part_holonyms())\n",
    "\n",
    "# Loop over the lemmas and check for antonyms\n",
    "for i in range(len(memory.lemmas())):\n",
    "   print(memory.lemmas()[i].antonyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: visit.v.01(go to see a place, as for entertainment)  \n",
      "\t Lemmas:['visit', 'see']\n",
      "Synset: travel_to.v.01(go to certain places as for sightseeing)  \n",
      "\t Lemmas:['travel_to', 'visit']\n",
      "Synset: visit.v.03(pay a brief visit)  \n",
      "\t Lemmas:['visit', 'call_in', 'call']\n",
      "Synset: visit.v.04(come to see in an official or professional capacity)  \n",
      "\t Lemmas:['visit', 'inspect']\n",
      "Synset: inflict.v.01(impose something unpleasant)  \n",
      "\t Lemmas:['inflict', 'bring_down', 'visit', 'impose']\n",
      "Synset: chew_the_fat.v.01(talk socially without exchanging too much information)  \n",
      "\t Lemmas:['chew_the_fat', 'shoot_the_breeze', 'chat', 'confabulate', 'confab', 'chitchat', 'chit-chat', 'chatter', 'chaffer', 'natter', 'gossip', 'jaw', 'claver', 'visit']\n",
      "Synset: visit.v.07(stay with as a guest)  \n",
      "\t Lemmas:['visit']\n",
      "Synset: visit.v.08(assail)  \n",
      "\t Lemmas:['visit']\n"
     ]
    }
   ],
   "source": [
    "# Pick a synsets\n",
    "visit = wn.synsets('visit')\n",
    "\n",
    "#  Output all the synsets\n",
    "visit_synsets = wn.synsets('visit', pos=wn.VERB)\n",
    "for sense in visit_synsets:\n",
    "    lemmas = [l.name() for l in sense.lemmas()]\n",
    "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go to see a place, as for entertainment\n",
      "['We went to see the Eiffel Tower in the morning']\n",
      "[Lemma('visit.v.01.visit'), Lemma('visit.v.01.see')]\n",
      "Synset('tour.v.01')\n",
      "Synset('travel.v.02')\n",
      "Synset('travel.v.03')\n"
     ]
    }
   ],
   "source": [
    "visit = wn.synset('visit.v.01')\n",
    "\n",
    "print(visit.definition())\n",
    "print(visit.examples())\n",
    "print(visit.lemmas())\n",
    "\n",
    "\n",
    "# WordNet hierarchy \n",
    "hyp = visit.hypernyms()[0]\n",
    "top = visit.root_hypernyms()[0]\n",
    "while hyp:\n",
    "    print(hyp)\n",
    "    if hyp == top:\n",
    "        break\n",
    "    if hyp.hypernyms():\n",
    "        hyp = hyp.hypernyms()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verbs are similar to nouns in that they are organized in a hierachy based on the hypernymy/hyponymy relation between synsets. However, verbs do not have a common top-level synset to reference to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visit\n",
      "visit\n",
      "None\n",
      "None\n",
      "visit\n"
     ]
    }
   ],
   "source": [
    "print(wn.morphy('visit'))\n",
    "print(wn.morphy('visit', wn.NOUN))\n",
    "print(wn.morphy('visit', wn.ADJ))\n",
    "print(wn.morphy('visit', wn.ADV))\n",
    "print(wn.morphy('visit', wn.VERB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: baseball.n.01(a ball game played with a bat and ball between two teams of nine players; teams take turns at bat trying to score runs)  \n",
      "\t Lemmas:['baseball', 'baseball_game']\n",
      "Synset: baseball.n.02(a ball used in playing baseball)  \n",
      "\t Lemmas:['baseball']\n",
      "Synset: football.n.01(any of various games played with a ball (round or oval) in which two teams try to kick or carry or propel the ball into each other's goal)  \n",
      "\t Lemmas:['football', 'football_game']\n",
      "Synset: football.n.02(the inflated oblong ball used in playing American football)  \n",
      "\t Lemmas:['football']\n"
     ]
    }
   ],
   "source": [
    "baseball_synsets = wn.synsets('baseball', pos=wn.NOUN)\n",
    "for sense in baseball_synsets:\n",
    "    lemmas = [l.name() for l in sense.lemmas()]\n",
    "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))\n",
    "\n",
    "football_synsets = wn.synsets('football', pos=wn.NOUN)\n",
    "for sense in football_synsets:\n",
    "    lemmas = [l.name() for l in sense.lemmas()]\n",
    "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bank.n.01') sloping land (especially the slope beside a body of water)\n",
      "Synset('depository_financial_institution.n.01') a financial institution that accepts deposits and channels the money into lending activities\n",
      "Synset('bank.n.03') a long ridge or pile\n",
      "Synset('bank.n.04') an arrangement of similar objects in a row or in tiers\n",
      "Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n",
      "Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n",
      "Synset('bank.n.07') a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n",
      "Synset('bank.n.09') a building in which the business of banking transacted\n",
      "Synset('bank.n.10') a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "Synset('bank.v.01') tip laterally\n",
      "Synset('bank.v.02') enclose with a bank\n",
      "Synset('bank.v.03') do business with a bank or keep an account at a bank\n",
      "Synset('bank.v.04') act as the banker in a game or in gambling\n",
      "Synset('bank.v.05') be in the banking business\n",
      "Synset('deposit.v.02') put into a bank account\n",
      "Synset('bank.v.07') cover with ashes so to control the rate of burning\n",
      "Synset('trust.v.01') have confidence or faith in\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "Synset('baseball.n.01') a ball game played with a bat and ball between two teams of nine players; teams take turns at bat trying to score runs\n",
      "Synset('baseball.n.02') a ball used in playing baseball\n"
     ]
    }
   ],
   "source": [
    "# Wu-Palmer\n",
    "\n",
    "baseball = wn.synset('baseball.n.01')\n",
    "football = wn.synset('football.n.01')\n",
    "\n",
    "print(wn.wup_similarity(baseball, football))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('football.n.01') any of various games played with a ball (round or oval) in which two teams try to kick or carry or propel the ball into each other's goal\n",
      "Synset('football.n.02') the inflated oblong ball used in playing American football\n",
      "Synset('football.n.01')\n"
     ]
    }
   ],
   "source": [
    "# Lesk algorithm\n",
    "\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "# look at the definitions for 'football'\n",
    "for ss in wn.synsets('football'):\n",
    "    print(ss, ss.definition())\n",
    "\n",
    "\n",
    "sentence = 'The quarterback threw the football for a touchdown.' \n",
    "print(lesk(sentence, 'football'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for the two algorithms were very different. The Wu-Palmer showed that the two words were strongly related to each other. This makes sense as both words are commonly played sports. The lesk algorithm was not entirely accurate on the definitions. The definition I used in the sentence was refering to the ball whereas the algorithm returned the definition for the game.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentiWordNet allows for a computer to interpret the tone of a particular sentence. It works by assining 3 scores to a word that rates how positive, negative, or objective it is. To get the analysis for an entire sentence, you would have to add up the positive/negative counts for each word and then you have the overall analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: starvation.n.02(the act of depriving of food or subjecting to famine)  \n",
      "\t Lemmas:['starvation', 'starving']\n",
      "Synset: starve.v.01(be hungry; go without food)  \n",
      "\t Lemmas:['starve', 'hunger', 'famish']\n",
      "Synset: starve.v.02(die of food deprivation)  \n",
      "\t Lemmas:['starve', 'famish']\n",
      "Synset: starve.v.03(deprive of food)  \n",
      "\t Lemmas:['starve', 'famish']\n",
      "Synset: crave.v.01(have a craving, appetite, or great desire for)  \n",
      "\t Lemmas:['crave', 'hunger', 'thirst', 'starve', 'lust']\n",
      "Synset: starve.v.05(deprive of a necessity and cause suffering)  \n",
      "\t Lemmas:['starve']\n",
      "Synset: starved.s.01(suffering from lack of food)  \n",
      "\t Lemmas:['starved', 'starving']\n"
     ]
    }
   ],
   "source": [
    "fast_synsets = wn.synsets('starving')\n",
    "for sense in fast_synsets:\n",
    "    lemmas = [l.name() for l in sense.lemmas()]\n",
    "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<starve.v.01: PosScore=0.0 NegScore=0.25>\n",
      "<starve.v.02: PosScore=0.0 NegScore=0.0>\n",
      "<starve.v.03: PosScore=0.0 NegScore=0.0>\n",
      "<crave.v.01: PosScore=0.5 NegScore=0.0>\n",
      "<starve.v.05: PosScore=0.0 NegScore=0.5>\n"
     ]
    }
   ],
   "source": [
    "senti_list = list(swn.senti_synsets('starve')) \n",
    "for item in senti_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there          :  Positive:    0.0    Negative:    0.0\n",
      "was            :  Positive:    0.0    Negative:    0.0\n",
      "way            :  Positive:    0.0    Negative:    0.0\n",
      "too            :  Positive:  0.125    Negative:   0.25\n",
      "much           :  Positive:  0.125    Negative:  0.125\n",
      "homework       :  Positive:    0.0    Negative:    0.0\n",
      "assigned       :  Positive:    0.0    Negative:    0.0\n",
      "over           :  Positive:    0.0    Negative:    0.0\n",
      "weekend        :  Positive:    0.0    Negative:    0.0\n"
     ]
    }
   ],
   "source": [
    "sentence = 'there was way too much homework assigned over the weekend'\n",
    "tokens = sentence.split()\n",
    "for token in tokens:\n",
    "   syn_list = list(swn.senti_synsets(token))\n",
    "   if syn_list:\n",
    "      syn = syn_list[0]\n",
    "      pos = syn.pos_score()\n",
    "      neg = syn.neg_score()\n",
    "\n",
    "      print(f'{token:15}:  Positive:  {pos:5}    Negative:  {neg:5}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall scores were not as negative as I feel that they should be. I wrote the sentence trying to get a negative result and the output only slightly leans negative. I think the issue is the word 'way' has a score of 0 whereas the phrase 'way too much' implies a more negative tone than 'too much.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collocation is predictable combination of words that are put together for a specific meaning. The words can be anything from nouns, verbs, adverbs, and adjectives. The words in the collocation can not be subsitited while keeping the same meaning. For example, 'heavy rain' is a no the same as 'strong rain.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import text4\n",
    "\n",
    "print(text4.collocations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(United States) =  0.015860349127182045\n",
      "p(United) =  0.0170573566084788\n",
      "p(States) =  0.03301745635910224\n",
      "pmi =  4.815657649820885\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "text = ' '.join(text4.tokens)\n",
    "vocab = len(set(text4))\n",
    "\n",
    "hg = text.count('United States')/vocab\n",
    "print(\"p(United States) = \",hg )\n",
    "h = text.count('United')/vocab\n",
    "print(\"p(United) = \", h)\n",
    "g = text.count('States')/vocab\n",
    "print('p(States) = ', g)\n",
    "pmi = math.log2(hg / (h * g))\n",
    "print('pmi = ', pmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "United States is very much so a collocation. It represents the name of a country as a whole."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
